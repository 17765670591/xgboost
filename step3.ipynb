{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial how to use [xgboost](https://github.com/dmlc/xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('bike.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10886 entries, 0 to 10885\n",
      "Data columns (total 12 columns):\n",
      "datetime      10886 non-null object\n",
      "season        10886 non-null int64\n",
      "holiday       10886 non-null int64\n",
      "workingday    10886 non-null int64\n",
      "weather       10886 non-null int64\n",
      "temp          10886 non-null float64\n",
      "atemp         10886 non-null float64\n",
      "humidity      10886 non-null int64\n",
      "windspeed     10886 non-null float64\n",
      "casual        10886 non-null int64\n",
      "registered    10886 non-null int64\n",
      "count         10886 non-null int64\n",
      "dtypes: float64(3), int64(8), object(1)\n",
      "memory usage: 1020.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There're **10 886** observations and **12** features.\n",
    "\n",
    "### High level\n",
    "1. There are no missing values.\n",
    "2. Most values are integers, few of them floats and only one an object (should be a date).\n",
    "3. season, weather are categorical variables (contains for possible values - 1, 2, 3, 4)\n",
    "\n",
    "\n",
    "### More detailed\n",
    "1. **datetime** - hourly date + timestamp\n",
    "2. **season** -  \n",
    "    1 = spring  \n",
    "    2 = summer  \n",
    "    3 = fall  \n",
    "    4 = winter  \n",
    "3. **holiday** - whether the day is considered a holiday\n",
    "4. **workingday** - whether the day is neither a weekend nor holiday\n",
    "5. **weather** -   \n",
    "    1: Clear, Few clouds, Partly cloudy, Partly cloudy   \n",
    "    2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist  \n",
    "    3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds  \n",
    "    4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog  \n",
    "6. **temp** - temperature in Celsius\n",
    "7. **atemp** - \"feels like\" temperature in Celsius\n",
    "8. **humidity** - relative humidity\n",
    "9. **windspeed** - wind speed\n",
    "10. **casual** - number of non-registered user rentals initiated\n",
    "11. **registered** - number of registered user rentals initiated\n",
    "12. **count** - number of total rentals\n",
    "\n",
    "\n",
    "\n",
    "## Target variableÂ¶\n",
    "\n",
    "The goal is predict - **count**\n",
    "Note: **count** = **registered** + **casual**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality function\n",
    "\n",
    "$$ \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\ln(p_i + 1) - \\ln(a_i+1))^2 }$$\n",
    "\n",
    "where  \n",
    "**n** is the number of hours in the test set  \n",
    "**pi** is your predicted count  \n",
    "**ai** is the actual count  \n",
    "**ln(x)** is the natural logarithm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Feature Engineering\n",
    "Let's extract day in separeted column (is needed for validation as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['datetime'] = pd.to_datetime( train['datetime'] )\n",
    "train['day'] = train['datetime'].map(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assing_test_samples(data, last_training_day=0.3, seed=1):\n",
    "    days = data.day.unique()\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(days)\n",
    "    test_days = days[: int(len(days) * 0.3)]\n",
    "    \n",
    "    data['is_test'] = data.day.isin(test_days)\n",
    "\n",
    "\n",
    "def select_features(data):\n",
    "    columns = data.columns[ (data.dtypes == np.int64) | (data.dtypes == np.float64) | (data.dtypes == np.bool) ].values    \n",
    "    return [feat for feat in columns if feat not in ['count', 'casual', 'registered'] and 'log' not in feat ] \n",
    "\n",
    "def get_X_y(data, target_variable):\n",
    "    features = select_features(data)\n",
    "        \n",
    "    X = data[features].values\n",
    "    y = data[target_variable].values\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "def train_test_split(train, target_variable):\n",
    "    df_train = train[train.is_test == False]\n",
    "    df_test  = train[train.is_test == True]\n",
    "    \n",
    "    X_train, y_train = get_X_y(df_train, target_variable)\n",
    "    X_test, y_test = get_X_y(df_test, target_variable)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "def fit_and_predict(train, model, target_variable):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target_variable)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return (y_test, y_pred)\n",
    "\n",
    "def post_pred(y_pred):\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    return y_pred\n",
    "\n",
    "def rmsle(y_true, y_pred, y_pred_only_positive=True):\n",
    "    if y_pred_only_positive: y_pred = post_pred(y_pred)\n",
    "        \n",
    "    diff = np.log(y_pred+1) - np.log(y_true+1)\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)\n",
    "\n",
    "##########\n",
    "\n",
    "def count_prediction(train, model, target_variable='count'):\n",
    "    (y_test, y_pred) = fit_and_predict(train, model, target_variable)\n",
    "\n",
    "    if target_variable == 'count_log': \n",
    "        y_test = train[train.is_test == True]['count']\n",
    "        y_pred = np.exp2(y_pred)\n",
    "        \n",
    "    return rmsle(y_test, y_pred)\n",
    "\n",
    "    \n",
    "def registered_casual_prediction(train, model):\n",
    "    (_, registered_pred) = fit_and_predict(train, model, 'registered')\n",
    "    (_, casual_pred) = fit_and_predict(train, model, 'casual')\n",
    "\n",
    "    y_test = train[train.is_test == True]['count']\n",
    "    y_pred = registered_pred + casual_pred\n",
    "    \n",
    "    return rmsle(y_test, y_pred)\n",
    "\n",
    "def log_registered_casual_prediction(train, model):\n",
    "    (_, registered_pred) = fit_and_predict(train, model, 'registered_log')\n",
    "    (_, casual_pred) = fit_and_predict(train, model, 'casual_log')\n",
    "   \n",
    "    y_test = train[train.is_test == True]['count']\n",
    "    y_pred = (np.exp2(registered_pred) - 1) + (np.exp2(casual_pred) -1)\n",
    "    \n",
    "    return rmsle(y_test, y_pred)\n",
    "    \n",
    "\n",
    "assing_test_samples(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Regressor\n",
    "The most simple one :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dummy', 1.5758678110942455)\n",
      "('xgboost', 0.71226527946687523)\n"
     ]
    }
   ],
   "source": [
    "print('dummy', count_prediction(train, DummyRegressor()))\n",
    "print('xgboost', count_prediction(train, xgb.XGBRegressor()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Let's a bit improve quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def etl_datetime(df):\n",
    "    df['year'] = df['datetime'].map(lambda x: x.year)\n",
    "    df['month'] = df['datetime'].map(lambda x: x.month)\n",
    "\n",
    "    df['hour'] = df['datetime'].map(lambda x: x.hour)\n",
    "    df['minute'] = df['datetime'].map(lambda x: x.minute)\n",
    "    df['dayofweek'] = df['datetime'].map(lambda x: x.dayofweek)\n",
    "    df['weekend'] = df['datetime'].map(lambda x: x.dayofweek in [5,6])\n",
    "\n",
    "    \n",
    "etl_datetime(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('xgboost', 0.71226527946687523)\n"
     ]
    }
   ],
   "source": [
    "print('xgboost', count_prediction(train, xgb.XGBRegressor()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict count = register + casual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('xgboost', 0.73669841949326831)\n"
     ]
    }
   ],
   "source": [
    "print('xgboost', registered_casual_prediction(train, xgb.XGBRegressor()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithm combination - count_log, registered_log, casual_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['{0}_log'.format('count')] = train['count'].map(lambda x: np.log2(x) )\n",
    "\n",
    "for name in ['registered', 'casual']:\n",
    "    train['{0}_log'.format(name)] = train[name].map(lambda x: np.log2(x+1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict count = exp(count_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('xgboost', 0.41322977213972051)\n"
     ]
    }
   ],
   "source": [
    "print('xgboost', count_prediction(train, xgb.XGBRegressor(), 'count_log'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict count = exp(registered_log) + exp(casual_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('xgboost', 0.39339177031871342)\n"
     ]
    }
   ],
   "source": [
    "print('xgboost', log_registered_casual_prediction(train, xgb.XGBRegressor()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with other models\n",
    "- DecisionTreeRegressor\n",
    "- RandomForestRegressor\n",
    "- ExtraTreesRegressor\n",
    "- GradientBoostingRegressor\n",
    "- AdaBoostRegressor\n",
    "- BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('decision_tree', 0.43716176533139672)\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    ('decision_tree', DecisionTreeRegressor()),\n",
    "##put here other algorithms (mentioned above)\n",
    "    \n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    print(model[0], log_registered_casual_prediction(train, model[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'n_estimators': 100, 'max_depth': 2}, 0.46000367817350141)\n",
      "({'n_estimators': 200, 'max_depth': 2}, 0.383063126639346)\n",
      "({'n_estimators': 300, 'max_depth': 2}, 0.36217291062931611)\n",
      "({'n_estimators': 100, 'max_depth': 5}, 0.33877146331666108)\n",
      "({'n_estimators': 200, 'max_depth': 5}, 0.3329926658794557)\n",
      "({'n_estimators': 300, 'max_depth': 5}, 0.33179067955100161)\n",
      "({'n_estimators': 100, 'max_depth': 10}, 0.33338905009262376)\n",
      "({'n_estimators': 200, 'max_depth': 10}, 0.33411251538787728)\n",
      "({'n_estimators': 300, 'max_depth': 10}, 0.33430611210836408)\n"
     ]
    }
   ],
   "source": [
    "for max_depth in [2, 5, 10]:\n",
    "    for n_estimators in [100, 200, 300]:\n",
    "        params = {'max_depth': max_depth, 'n_estimators': n_estimators}\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        print(params, log_registered_casual_prediction(train, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try play around with subsample, learning_rate and ohers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
